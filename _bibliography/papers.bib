---
---

@inproceedings{luo2026refinelab,
  abbr={AAAI},
  title={Better datasets start from refinelab: Automatic optimization for high-quality dataset refinement},
  author={Luo*, Xiaonan and Huang*, Yue and He, Ping and Zhang, Xiangliang},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2026},
  bibtex_show={true},
  selected={true},
  arxiv={2511.06530},
  html={https://arxiv.org/abs/2511.06530},
  abstract={High-quality datasets are crucial for training effective machine learning models. This paper presents RefineLab, an automated framework for optimizing dataset refinement processes to improve data quality and model performance.}
}

@inproceedings{wang2025adareasoner,
  abbr={NeurIPS},
  title={AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking},
  author={Wang, Xiangqi and Huang, Yue and Wang, Yanbo and Luo, Xiaonan and Guo, Kehan and Zhou, Yujun and Zhang, Xiangliang},
  booktitle={Advances in Neural Information Processing Systems},
  year={2025},
  note={Spotlight},
  bibtex_show={true},
  selected={true},
  arxiv={2505.17312},
  html={https://arxiv.org/abs/2505.17312},
  abstract={AdaReasoner introduces an adaptive reasoning framework that enables large language models to dynamically adjust their reasoning strategies based on problem complexity and context.}
}

@inproceedings{huang2025chemorch,
  abbr={NeurIPS},
  title={ChemOrch: Empowering LLMs with Chemical Intelligence via Synthetic Instructions},
  author={Huang, Yue and Jiang, Zhengzhe and Luo, Xiaonan and Guo, Kehan and Zhuang, Haomin and Zhou, Yujun and Yuan, Zhengqing and Sun, Xiaoqi and Schleinitz, Jules and Wang, Yanbo and Zhang, Shuhao and Surve, Mihir and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  booktitle={Advances in Neural Information Processing Systems},
  year={2025},
  bibtex_show={true},
  selected={true},
  arxiv={2509.16543},
  html={https://arxiv.org/abs/2509.16543},
  abstract={ChemOrch presents a novel approach to enhancing large language models with specialized chemical knowledge through carefully designed synthetic instructions, enabling more accurate chemical reasoning and prediction.}
}

@inproceedings{yu2025torpor,
  abbr={ATC},
  title={Torpor: GPU-Enabled Serverless Computing for Low-Latency, Resource-Efficient Inference},
  author={Yu, Mingyu and Wang, Ao and Chen, Dong and Yu, Haoxuan and Luo, Xiaonan and Li, Zhuzhong and Wang, Wei and Chen, Ruichuan and Nie, Dapeng and Yang, Kaiyuan and Chen, Xiaobing and Liu, Mingyang and Zhang, Yijia and Yang, Mao},
  booktitle={USENIX Annual Technical Conference},
  year={2025},
  bibtex_show={true},
  selected={true},
  arxiv={2306.03622},
  html={https://arxiv.org/abs/2306.03622},
  abstract={Torpor presents a GPU-enabled serverless computing system that achieves low-latency, resource-efficient inference by intelligently managing GPU memory and computation resources.}
}
