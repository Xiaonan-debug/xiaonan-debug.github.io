{
  "basics": {
    "name": "Xiaonan Luo",
    "label": "Ph.D. Student in Computer Science",
    "image": "",
    "email": "xluo6@nd.edu",
    "phone": "",
    "url": "https://xiaonan-debug.github.io",
    "summary": "First-year Ph.D. student at the University of Notre Dame, focusing on large language models, data-centric AI, and machine learning systems.",
    "location": {
      "address": "Computer Science and Engineering",
      "postalCode": "IN 46556",
      "city": "Notre Dame",
      "countryCode": "US",
      "region": "Indiana"
    },
    "profiles": [
      {
        "network": "LinkedIn",
        "username": "xiaonan-luo-3238ba205",
        "url": "https://www.linkedin.com/in/xiaonan-luo-3238ba205"
      },
      {
        "network": "Google Scholar",
        "username": "Xiaonan Luo",
        "url": "https://scholar.google.com/citations?user=35otsO4AAAAJ"
      }
    ]
  },
  "work": [],
  "volunteer": [],
  "education": [
    {
      "institution": "University of Notre Dame",
      "location": "Notre Dame, IN, USA",
      "url": "https://www.nd.edu/",
      "area": "Computer Science and Engineering",
      "studyType": "Ph.D.",
      "startDate": "2025-01-01",
      "endDate": "",
      "score": "",
      "courses": []
    },
    {
      "institution": "Hong Kong University of Science and Technology (HKUST)",
      "location": "Hong Kong",
      "url": "https://hkust.edu.hk/",
      "area": "Computer Science",
      "studyType": "Bachelor of Engineering",
      "startDate": "2020-09-01",
      "endDate": "2024-06-01",
      "score": "",
      "courses": []
    }
  ],
  "awards": [],
  "certificates": [],
  "publications": [
    {
      "name": "Better datasets start from refinelab: Automatic optimization for high-quality dataset refinement",
      "publisher": "AAAI Conference on Artificial Intelligence",
      "releaseDate": "2026-01-01",
      "url": "https://arxiv.org/abs/2511.06530",
      "summary": "Luo*, Xiaonan and Huang*, Yue and He, Ping and Zhang, Xiangliang. High-quality datasets are crucial for training effective machine learning models. This paper presents RefineLab, an automated framework for optimizing dataset refinement processes to improve data quality and model performance."
    },
    {
      "name": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking",
      "publisher": "Advances in Neural Information Processing Systems (NeurIPS) - Spotlight",
      "releaseDate": "2025-12-01",
      "url": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=35otsO4AAAAJ&citation_for_view=35otsO4AAAAJ:9yKSN-GCB0IC",
      "summary": "Wang, Xiangqi and Huang, Yue and Wang, Yanbo and Luo, Xiaonan and Guo, Kehan and Zhou, Yujun and Zhang, Xiangliang. AdaReasoner introduces an adaptive reasoning framework that enables large language models to dynamically adjust their reasoning strategies based on problem complexity and context."
    },
    {
      "name": "ChemOrch: Empowering LLMs with Chemical Intelligence via Synthetic Instructions",
      "publisher": "Advances in Neural Information Processing Systems (NeurIPS)",
      "releaseDate": "2025-12-01",
      "url": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=35otsO4AAAAJ&citation_for_view=35otsO4AAAAJ:qjMakFHDy7sC",
      "summary": "Huang, Yue and Jiang, Zhengzhe and Luo, Xiaonan and Guo, Kehan and Zhuang, Haomin and Zhou, Yujun and others. ChemOrch presents a novel approach to enhancing large language models with specialized chemical knowledge through carefully designed synthetic instructions, enabling more accurate chemical reasoning and prediction."
    },
    {
      "name": "Torpor: GPU-Enabled Serverless Computing for Low-Latency, Resource-Efficient Inference",
      "publisher": "USENIX Annual Technical Conference (ATC)",
      "releaseDate": "2025-07-01",
      "url": "https://arxiv.org/abs/2306.03622",
      "summary": "Yu, Mingyu and Wang, Ao and Chen, Dong and Yu, Haoxuan and Luo, Xiaonan and Li, Zhuzhong and others. Torpor presents a GPU-enabled serverless computing system that achieves low-latency, resource-efficient inference by intelligently managing GPU memory and computation resources."
    }
  ],
  "skills": [
    {
      "name": "Machine Learning",
      "level": "Advanced",
      "icon": "fa-solid fa-brain",
      "keywords": [
        "Large Language Models",
        "Data-Centric AI",
        "Deep Learning",
        "PyTorch",
        "TensorFlow",
        "Hugging Face Transformers"
      ]
    },
    {
      "name": "Programming",
      "level": "Advanced",
      "icon": "fa-solid fa-code",
      "keywords": [
        "Python",
        "C/C++",
        "Java",
        "JavaScript",
        "Git",
        "Docker",
        "Linux",
        "CUDA"
      ]
    }
  ],
  "languages": [
    {
      "language": "Chinese",
      "fluency": "Native speaker",
      "icon": ""
    },
    {
      "language": "English",
      "fluency": "Fluent",
      "icon": ""
    }
  ],
  "interests": [
    {
      "name": "Research",
      "icon": "fa-solid fa-microscope",
      "keywords": [
        "Reasoning and Tool-Augmented Foundation Models",
        "Data-Centric Optimization",
        "Scientific AI",
        "Efficient AI Systems"
      ]
    }
  ],
  "references": [],
  "projects": []
}
